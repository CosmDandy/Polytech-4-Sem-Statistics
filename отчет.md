# Отчет по практике
15 страниц, титульник, как на курсовую, оформление по ГОСТ

Введение, где цель и задачи
Теоретическая часть
Практическая часть
Заключение
Список литературы
Приложение (если необходимо)
***

***

# Введение

Современное образование становится все более адаптивным и ориентированным на потребности студентов. В этом контексте улучшение качества образования становится ключевой задачей, и совершенствование учебных курсов является неотъемлемой частью этой стратегии. Настоящий отчет представляет результаты исследовательского проекта, целью которого является улучшение существующего курса статистики.

**Цель и задачи**

**Целью** данного проекта является повышение эффективности и качества курса статистики, предлагаемого нашим учебным заведением. Для достижения этой цели были поставлены следующие **задачи**:

1. **Анализ текущего состояния курса:** Оценить текущий уровень эффективности и удовлетворенности студентов существующим курсом статистики. Это включает в себя анализ учебных материалов, методов преподавания и обратной связи от студентов.

2. **Идентификация учебных потребностей:** Выявить потребности студентов и требования современного рынка труда в области статистики. Это позволит более точно адаптировать курс к потребностям студентов и работодателей.

3. **Разработка улучшений курса:** На основе анализа и идентификации потребностей разработать конкретные улучшения, которые помогут повысить качество и актуальность курса статистики.

4. **Внедрение изменений:** Реализовать предложенные улучшения в рамках курса статистики и провести их оценку на практике.

Этот отчет представляет подробный анализ выполненных задач и результатов, а также предложения по дальнейшему улучшению курса статистики, с учетом потребностей обучающихся и требований современного мира статистики и данных.

---

# Теоретическая часть
## Типы признаков / данных
В мире анализа данных и статистики, разнообразие типов признаков и данных играет важную роль в понимании и интерпретации информации. Признаки представляют собой характеристики или переменные, которые описывают объекты или события, а данные представляют собой значения или наблюдения этих признаков. От правильного определения типов признаков зависит выбор подходящих статистических методов и моделей для анализа данных.

В данной главе мы рассмотрим различные типы признаков и данных, которые широко используются в анализе данных. В данном случае под данными имеются ввиду переменные и наоборот. 

![[Типы данных.png]]

***

### Категориальные / Качественные признаки
**Категориальные / Качественные признаки** - это признаки каждое значение которых указывает на принадлежность объекта к определенной группе. Цифры в данном случае обозначают свойства объекта, служат маркерами, и не имеют математического смысла.

Категориальные / Качественные признаки, в свою очередь, можно поделить на **номинальные** и **порядковые**.
***
#### Номинальные признаки
**Номинальные признаки** применяются для обозначения категорий или признаков, которые нельзя классифицировать по возрастанию или убыванию, т.е они только содержат информацию о принадлежности объекта к какому-то классу.

Примеры:
- Группы крови (Каждой группе крови можно дать число обозначающее ее.)
- Типы горных пород и т.п. (Каждой горной породе можно дать число обозначающее ее.)
***
#### Порядковые / Ранговые признаки
**Порядковые / Ранговые признаки** отличаются от номинальных тем, что в них появляется отношения порядка. То есть здесь у нас значения не только разделяют объекты на классы, но и определенным образом упорядочивают их.

Примеры:
- Список участников забега (Список отражает кто из участиков быстрее, а кто медленнее, но не показывает на сколько быстрее или медленнее)
- Другие примеры в которых подразумевается сравнивание результатов
***

### Количественные / Числовые признаки
**Количественные / Числовые признаки** отображают количество чего-то. 

Их в свою очередь, можно поделить на **дискретные** и **непрерывные**.
***
#### Непрерывные признаки
Непрерывные признаки - это признаки, которые могут принимать любое значение из диапазона возможных значений.

К примеру $1, 2.3, 3.3, 4, 8 \frac{2}{3}, \dots$ или $[10, 30]$. 
***
#### Дискретные признаки
Дискретные признаки - это признаки, которые могут принимать только целые значения из ряда возможных значений.

К примеру $1, 2, 3, 4, \dots$

Такие переменные не могут быть дробными, то есть $3.5$ не дискретная переменная.

***

## Введение в Matplotlib
### Установка
Чтобы установить библиотеку matplotlib достаточно прописать в консоли:

```bash
pip install matplotlib 
```

### Простой пример использования
Чтобы начать пользоваться библиотекой в своём коде достаточно импортировать pyplot:

```Python
import matplotlib.pyplot as plt
```

Если вы используете Jupyter, то также следует добавить строчку кода, которая включает отображения графиков внутри jupyter notebook:

```Python
%matplotlib inline
```

Matplotlib отображает ваши данные на рисунке `Figures` (например, окнах, виджеты Jupyter и т.д.), каждый из которых может содержать одну или несколько осей `Axes`, область, где точки могут быть указаны в терминах координат x-y (или полярных координатах, x-y-z в 3D и т.д.). Самый простой способ создания `Figure` с `Axes` - это использование `plt.subplots`. Затем мы можем использовать `Axes.plot`, чтобы нарисовать данные по осям:

```Python
fig, ax = plt.subplots() # Создание области, которая содержит единственный график.
ax.plot([1, 2, 3, 4], [1, 4, 2, 3]) # Вывод данных на график.
plt.show() # Рендер области с графиками.
```

![[plot1.png]]
*Результат выполнения кода выше.*

### Части графика 
Части `Figure`:
![[parts_of_figure.png]]

##### `Figure`
Рисунок в которой строятся оси координат. `Figure` отслеживает все дочерние `Axes`, группы "специальных" `Artists` (названия, подписи к рисункам, цветовые панели и т.д.) и даже вложенные под рисунки.

##### `Axes`
Оси (`Axes`) - это подкласс `Artist`, прикрепленный к `Figure`, который содержит область для построения данных и обычно включает в себя два (или три в случае 3D) оси `Axis` (помните о разнице между `Axes` и `Axis`), которые обеспечивают ticks и ticks labels для обеспечения масштабирования данных в осях. Каждая ось также имеет заголовок (задается с помощью `set_title()`), x-метку (задается с помощью `set_xlabel()`) и y-метку, заданную с помощью `set_ylabel()`).

Класс `Axes` и его функции-члены являются основной точкой входа для работы с интерфейсом ООП, и в них определено большинство методов построения графиков (например, `ax.plot()`, показанный выше, использует метод построения графиков).

##### `Axis`
Эти объекты задают масштаб и пределы и генерируют `ticks` (метки на оси) и `ticklabels` (строки, обозначающие отметки). Расположение `ticks` определяется объектом `Locator`, а строки `ticklabel` форматируются с помощью `Formatter`. Сочетание правильного `Locator` и `Formatter` обеспечивает точный контроль над расположением `tick` и `labels`.

##### `Artist`
По сути, все, что видно на рисунке, принадлежит к классу `Artist` (фигура, оси и осевые объекты). Сюда входят `Text` объекты, объекты `Line2D`, объекты `collections`, объекты `Patch` и т.д. Когда `Figure` отрисована, все `Artist` рисуются на холсте. Большинство объектов класса `Artist` привязаны к осям; такие `Artist` объекты не могут быть перемещены или разделяться несколькими `Axes`.

### Типы входа для функций отрисовки
В качестве входа функции отрисовки (`plot`) ожидают увидеть [[Pandas|np.array]] или объект, который может быть конвертирован `np.array` с помощью `np.asarray`. 

```Python
b = np.matrix([[1, 2], [3, 4]])
b_asarray = np.asarray(b)
```

#### [[Pandas]]
`pd.DataFrame` или `dict-like` объекты можно передавать в качестве аргумента `data` и генерировать графики указывая `str` соответствующие оси x, y.

```Python
np.random.seed(19680801)  # seed the random number generator.
data = {'a': np.arange(50),
        'c': np.random.randint(0, 50, 50),
        'd': np.random.randn(50)}
data['b'] = data['a'] + 10 * np.random.randn(50)
data['d'] = np.abs(data['d']) * 100

fig, ax = plt.subplots(figsize=(5, 2.7), layout='constrained')
ax.scatter('a', 'b', c='c', s='d', data=data)
ax.set_xlabel('entry a')
ax.set_ylabel('entry b')
```

![[plot2.png]]
*Результат выполнения кода выше*

### Styling Arists
Большинство методов построения графиков имеют параметры оформления для `Artist`, доступные либо при вызове метода построения графиков, либо из "setter" на художнике. На графике ниже мы вручную задаем цвет, ширину линии и стиль линий `Artist`, созданных с помощью `plot`, и мы задаем стиль линии второй строки постфактум с помощью `set_linestyle`.

```Python
fig, ax = plt.subplots(figsize=(5, 2.7))
x = np.arange(len(data1))
ax.plot(x, np.cumsum(data1), color='blue', linewidth=3, linestyle='--')
l = ax.plot(x, np.cumsum(data2), color='orange', linewidth=2)
l.set_linestyle(':')
```

![[plot3.png]]

### Добавление меток на график
`set_xlabel`, `set_ylabel`, и  `set_title` используются, чтобы добавить текст в соответствующие места на графике. Текст также может быть напрямую добавлен на график с использованием метода `text`:

```Python
mu, sigma = 115, 15
x = mu + sigma * np.random.randn(10000)
fig, ax = plt.subplots(figsize=(5, 2.7), layout='constrained')
# the histogram of the data
n, bins, patches = ax.hist(x, 50, density=True, facecolor='C0', alpha=0.75)

ax.set_xlabel('Length [cm]')
ax.set_ylabel('Probability')
ax.set_title('Aardvark lengths\n (not really)')
# Using Latex in text
ax.text(75, .025, r'$\mu=115,\ \sigma=15$')
ax.axis([55, 175, 0, 0.03])
ax.grid(True)
```

![[plot4.png]]
*Результат выполнения кода выше*

>[!Note] Стоит заметить, что matplotlib поддерживает TeX выражение в любом `text` выражение.

#### `annotation`
Мы также можем комментировать точки на графике, часто соединяя стрелку, указывающую на `xy`, с фрагментом текста в `xytext`:

```Python
fig, ax = plt.subplots(figsize=(5, 2.7))

t = np.arange(0.0, 5.0, 0.01)
s = np.cos(2 * np.pi * t)
line, = ax.plot(t, s, lw=2)

ax.annotate('local max', xy=(2, 1), xytext=(3, 1.5),
            arrowprops=dict(facecolor='black', shrink=0.05))
            
ax.set_ylim(-2, 2)
```

![[plot5.png]]
*Результат выполнения кода выше*

>[!note] Стоит обратить внимания, что для добавления аннотации или текста на график указываются координаты этой точки в системе координат данных.



## Введение в Pandas
### Установка библиотеки
Чтобы установить библиотеку pandas достаточно прописать в консоли:

```bash
pip install pandas
```

### Основы pandas
Библиотека pandas - это мощный инструмент для анализа данных и манипуляций с ними в языке программирования Python. Она предоставляет высокопроизводительные и простые в использовании структуры данных, такие как DataFrame, для обработки и анализа табличных данных.

В pandas существует две основные структуры данных:
- `Series` - 1D однородно-типизированный массив. Можно выполнять все те же операции, что и с векторами.
- `DataFrame` - 2D, изменяемая по размеру табличная структура с потенциально разнородно типизированным столбцами.

Чтобы использовать pandas достаточно импортировать:

```Python
import pandas as pd
```

Pandas является надстройкой на Numpy, поэтому у них похожий синтаксис и большинство методов и функций numpy можно применять к `Series` и `DataFrame`.

### `DataFrame`
Как упоминалось выше `DataFrame` это таблица, в которой столбцы могут иметь различные типы данных. Пройдёмся по основам взаимодействия с ней.

![[dataframe_pic.png]]
*Схематичное изображение `DataFrame`*

Пример создания и вывода таблицы в Jupyter notebook:

```Python
In [1]: df = pd.DataFrame(
   ...:    {
   ...:        "Name": [
   ...:            "Braund, Mr. Owen Harris",
   ...:            "Allen, Mr. William Henry",
   ...:            "Bonnell, Miss. Elizabeth",
   ...:        ],
   ...:        "Age": [22, 35, 58],
   ...:        "Sex": ["male", "male", "female"],
   ...:    }
   ...: )
   ...: 

In [2]: df
Out[2]: 
                       Name  Age     Sex
0   Braund, Mr. Owen Harris   22    male
1  Allen, Mr. William Henry   35    male
2  Bonnell, Miss. Elizabeth   58  female
```

Каждый столбец таблицы - это `Series` и получить столбец можно различными способами:

```Python
In [3]: # Возьмём столбец Age для примера.
   ...: col = df["Age"]
   ...: # Также его можно взять с помощью loc
   ...: col = df.loc[:, "Age"]
   ...: # Или по индекса с помощью iloc
   ...: col = df.iloc[:, 1]
   ...: col
Out[3]: 
0    22
1    35
2    58
```

Конкретный элемент, как `DataFrame` можно взять по индексу или метке ("Age" например метка)  используя свойство `.iloc[i_index, j_column]` или `.loc[index, column]`.

```Python
In [4]: df.loc[0, "Name"]
Out[4]: 'Braund, Mr. Owen Harris'

In [5]: df.iloc[0, 0]
Out[5]: 'Braund, Mr. Owen Harris'
```

Также в pandas можно делать срезы и накладывать булевые маски:

```Python
In [6]: df.loc[:1, ["Name", "Sex"]]
Out[6]: 
                      Name  Sex 
0  Braund, Mr. Owen Harris male 
1 Allen, Mr. William Henry male

In [7]: df.iloc[:2, [0, 2]]
Out[7]: 
				      Name  Sex 
0  Braund, Mr. Owen Harris male 
1 Allen, Mr. William Henry male

In [8]: df[df["Age"] > 30]
Out[8]:
					  Name  Sex 
0  Braund, Mr. Owen Harris male 
1 Allen, Mr. William Henry male
```

### `Series`
`Series` как `ndarray` имеет различные методы, вроде `sum`, `min`, `max`, `mean`, `std` и т.д. (можно посчитать сразу все эти свойства пользуясь методом `describe`). Также `Series` доступны математические операции (`+`, `-`, `*`, `/`,…) или логические операции (`<`, `>`, `==`,…) работающие поэлементно.

```Python
In [9]: df["Age"] + df["Age"] + 10 == df["Age"] * 2 + 10
Out[9]: 
0 True 
1 True 
2 True 
Name: Age, dtype: bool

In [10]: df["Age"].mean()
Out[10]: 38.333333333333336
```

Чтобы привести `Series` к другому формату данных достаточно воспользоваться методом `astype`:
```Python
In [11]: pd.Series([1, 0, 1]).astype(bool)
Out[11]:
0 True 
1 False
2 True 
dtype: bool
```

### Group by
Вычисление статистики (например, среднего возраста) для каждой категории столбца (например, мужчина/женщина в столбце Age) является обычной задачей. Метод `groupby` используется для поддержки этого типа операций. Это вписывается в более общий шаблон разделения-применения-комбинирования:
- **Разделить** данные на группы
- **Применить** функцию к каждой группе независимо
- **Объединить** результат в структуре данных
Шаги "применить" и "объединить" обычно выполняются одновременно в pandas.

```Python
In [12]: df.groupby("Sex")["Age"].mean()
Out[12]:
Sex 
female 58.0 
male 28.5 
Name: Age, dtype: float64
```

![[groupby.png]]
*Поэтапная иллюстрация кода выше (titanic=df).*

### Вычисление количества элементов категории
Иногда требуется подсчитать количество каждого уникального элемента `Series`. Для этого применяется метод `value_counts`.

```Python
In [13]: df["Sex"].unique()
Out[13]: array(['male', 'female'], dtype=object)

In [14]: df["Sex"].value_counts()
Out[14]:
male 2 
female 1 
Name: Sex, dtype: int64
```

### Дополнительно
Рассмотрим часто используемые методы и свойства для взаимодействия с таблицами:
- `sort_index()` - сортирует по индексам.
- `sort_values()` - сортирует по значениям.
- `shape` - содержит информацию о форме `DataFrame`/`Series`.
- `T` - содержит транспонированную таблицу.
- `index` - содержит индексы.
- `columns` - содержит названия столбцов.




# Практическая часть
## Вариационный ряд
> Вариационный ряд представляет собой упорядоченный набор значений признака, а также соответствующие им частоты или количество наблюдений.

Вариационный ряд используется для выполнения следующих задач:
1. Изучение распределения данных: Вариационный ряд позволяет визуально представить распределение данных и понять, как они распределены по значению. Это особенно полезно при анализе больших наборов данных, где сложно сразу оценить распределение.
2. Вычисление статистических мер: Вариационный ряд позволяет легко вычислить различные статистические меры, такие как среднее значение, медиана, квартили, минимальное и максимальное значения. Эти меры помогают описать и понять свойства данных.
3. Оценка экстремальных значений: Вариационный ряд позволяет идентифицировать экстремальные значения данных, такие как выбросы или значения, находящиеся на краях распределения. Это помогает выявить необычные или потенциально ошибочные наблюдения.
4. Построение гистограммы и полигона частот: На основе вариационного ряда можно построить гистограмму или полигон частот, которые визуально отображают распределение данных и помогают исследовать их частоту или относительную частоту.

Вариационный ряд состоит из следующих элементов:
- **Варианты** 
- **Абсолютные частоты** или **Относительные частоты**

Например, предположим, что у нас есть набор данных о возрасте людей, состоящий из следующих значений:

| Возраст | 32  | 28  | 25  | 40  | 32  | 30  | 25  | 28  |
| ------ | --- | --- | --- | --- | --- | --- | --- | --- |

Ряд отсортированный в порядке возрастания будет выглядеть следующим образом
```Python
data_sort = data.sort_values()  
print(data_sort.tolist())
```

```
[25, 25, 25, 28, 28, 30, 32, 32, 40]
```

%%
**Вариационный ряд с абсолютными частотам** и **Вариационный ряд с относительными частотами** для этого набора данных будет выглядеть следующим образом

| Варианты           | 25  | 28  | 30  | 32  | 40  |
| ------------------ |:---:|:---:|:---:|:---:|:---:|
| Абсолютные частоты |  3  |  2  |  1  |  2  |  1  |

| Варианты              |  25   |  28   |  30   |  32   |  40   |
| --------------------- |:-----:|:-----:|:-----:|:-----:|:-----:|
| Относительные частоты | 0.333 | 0.222 | 0.111 | 0.222 | 0.111 |

Рассмотрим каждый элемент вариационного ряда подробнее. 
%%

***
### Варианты
> В контексте статистики, термин **"варианты"** относится к уникальным значениям признака, распределенным в порядке возрастания

**Варианты** значений для данных о возрасте людей будут выглядеть следующим образом:

```Python
unique = sorted(data.unique())  
print(unique)
```

```
[25, 28, 30, 32, 40]
```

Метод `.unique()` используется для получения уникальных значений из массива данных. Результатом этого метода будет новый массив, содержащий только уникальные элементы из исходного массива `data`.

Функция `sorted()` применяется к полученному массиву уникальных значений для их сортировки в порядке возрастания.

***
### Вариационный ряд с абсолютными частотам
> **Вариационный ряд с абсолютными частотами** представляет собой упорядоченный список значений признака вместе с соответствующими **абсолютными частотами**, которые показывают, сколько раз каждое значение встречается в наборе данных.

Для создания вариационного ряда с абсолютными частотами необходимо пройти по всем значениям признака и посчитать, сколько раз каждое значение появляется в данных. Затем значения признака упорядочиваются в порядке возрастания или убывания, а ряду присваиваются соответствующие абсолютные частоты.

```Python
freq = pd.Series(data_sort).value_counts().sort_index()  
freq = pd.DataFrame(freq, index=unique, columns=["Абсолютные частоты"]).T  
freq
```

|                    | 25  | 28  | 30  | 32  | 40  |
| ------------------ |:---:|:---:|:---:|:---:|:---:|
| Абсолютные частоты |  3  |  2  |  1  |  2  |  1  |

***
### Вариационный ряд с относительными частотам
> **Вариационный ряд с относительными частотами** представляет собой вариационный ряд, где вместо абсолютных частот используются относительные частоты. **Относительная частота** указывает на долю каждого значения признака относительно общего количества наблюдений.

Для создания вариационного ряда с относительными частотами необходимо разделить абсолютные частоты на общее количество наблюдений. Это позволяет нам получить представление о том, как часто каждое значение признака встречается относительно всего набора данных.

```Python
rel_freq = pd.Series(data_sort).value_counts().sort_index() / len(data_sort)  
rel_freq = pd.DataFrame(rel_freq, index=unique, columns=["Относительные частоты"]).T  
rel_freq
```

|                       |  25   |  28   |  30   |  32   |  40   |
| --------------------- |:-----:|:-----:|:-----:|:-----:|:-----:|
| Относительные частоты | 0.333 | 0.222 | 0.111 | 0.222 | 0.111 |

***

### Полигон абсолютных и относительных частот вариационного ряда
%%
## Полигон абсолютных и относительных частот вариационного ряда
%%

> Полигон абсолютных и относительных частот вариационного ряда является графическим представлением распределения значений признака и их соответствующих частот. Он помогает визуализировать данные и понять их распределение на графике.

Для полигона **абсолютных частот**, на оси абсцисс откладываются значения признака, а на оси ординат - абсолютные частоты, которые показывают, сколько раз каждое значение встречается в наборе данных. Затем точки с заданными координатами соединяются линиями, образуя полигон, который отображает вариации абсолютных частот признака.

```Python
fig = px.line(x=unique, y=freq.iloc[0], markers=True, title='Полигон частот вариационного ряда')  
fig.show()
```
![[newplot.png]]

Для полигона **относительных частот**, на оси абсцисс также откладываются значения признака, а на оси ординат - относительные частоты, которые показывают, какую долю составляет каждое значение от общего числа наблюдений. Относительные частоты обычно выражаются в виде десятичных долей или процентов. Затем точки с заданными координатами соединяются линиями, образуя полигон относительных частот.

```Python
fig = px.line(x=unique, y=rel_freq.iloc[0], markers=True, title='Полигон относительных частот вариационного ряда')  
fig.show()
```
![[newplot1.png]]

Построение полигона абсолютных и относительных частот позволяет визуально анализировать распределение значений признака и выявлять особенности, такие как пики, моды, симметрию или асимметрию в данных. Это помогает лучше понять характеристики набора данных и делать выводы о его распределении.

***

## Интервальный вариационный ряд
%%
интервальный ряд распределения относительных частот вариационного ряда и построить гистограмму интервального ряда относительных частот
%%

> Интервальный вариационный ряд является особым видом вариационного ряда. Вместо того, чтобы перечислять каждое отдельное значение признака, интервальный вариационный ряд группирует значения в заданные интервалы.

Интервальный вариационный ряд состоит из интервалов значений признака и их соответствующих частот (абсолютных или относительных). Каждый интервал представляет диапазон значений, в котором находятся наблюдаемые значения признака. Частота интервала указывает, сколько значений попадает в этот интервал.

### Количество интервалов
> Количество интервалов в интервальном вариационном ряду определяет, сколько равных по ширине интервалов используется для группировки данных. Это важный параметр, который влияет на способ представления и анализа данных.

Когда имеется большое количество уникальных значений или широкий диапазон данных, интервальный вариационный ряд помогает упростить их представление. Вместо перечисления каждого значения в отдельности, данные группируются в интервалы, которые представляют диапазоны значений.

Выбор оптимального количества интервалов зависит от различных факторов, включая размер выборки, размах данных, природа переменной и цель анализа. Часто используются статистические методы, такие как формула Стерджесса для определения рекомендуемого количества интервалов.

$$k = \lceil \log_2 n \rceil + 1 \text{ или } k = \lceil 3.222 \lg n \rceil + 1 
\tag{формула Стерджесса}$$
где 
- $n$ - количество элементов вариационного ряда,

```Python
k = int(np.ceil(np.log2(len(data_sort)) + 1))  
print(f'Количество интервалов: {k}')
```

### Шаг интервала
> Шаг интервала в интервальном вариационном ряду представляет собой разницу между верхними или нижними границами соседних интервалов. Он определяет ширину каждого интервала и используется для группировки данных в интервальный ряд.

$$h = \frac{max(x) - min(x)}{k}$$
где
- $max(x)$ - максимальное значение вариационного ряда,
- $min(x)$ - минимальное значение вариационного ряда,
- $k$ - количество интервалов. 

```Python
h = (data_sort.max() - data_sort.min()) / k  
print(f'Шаг интервала: {h}')
```

### Интервальный вариационный ряд

Реализация интервального вариационного ряда на питоне выглядит следующим образом:
```Python
intervals = pd.Series([data_sort.min() + i * h for i in range(k+1)])  
print(intervals.tolist())
```
- `data_sort`: Это переменная, которая содержит отсортированный список данных.
- `k`: Это переменная, которая представляет количество интервалов, которые требуется создать в интервальном вариационном ряду.
- `h`: Это переменная, которая представляет шаг интервала.

### Распределение абсолютных частот интервального вариационного ряда

```Python
freq_intervals = pd.Series(data_sort).value_counts(bins=8).sort_index().values  
freq_intervals = pd.DataFrame(freq_intervals, index=intervals_mean, columns=["Частота"]).T  
freq_intervals
```

|             | 25.40-26.80 | 26.80-28.20 | 28.20-29.60 | 29.60-31.00 | 31.00-32.40 | 32.40-33.80 | 33.80-35.20 | 35.20-36.60 |
| ----------- | ----------- | ----------- | ----------- | ----------- | ----------- | ----------- | ----------- | ----------- |
| **Абсолютная частота** | 6           | 16          | 20          | 26          | 19          | 8           | 3           | 2           |

В данном коде используются следующие функции и методы из библиотеки Pandas:
1. `pd.Series()`: Это функция, которая создает объект Series в Pandas. В данном коде, она используется для создания объекта Series `data_sort`, который содержит отсортированные значения данных.
2. `value_counts()`: Это метод, применяемый к объекту Series. Он подсчитывает количество уникальных значений в объекте Series и возвращает результат в виде нового объекта Series, где индексы - это уникальные значения, а значения - их абсолютные частоты. В данном коде, `value_counts()` используется для подсчета абсолютных частот значений в объекте Series `data_sort`.
3. `bins`: Параметр метода `value_counts()`, который указывает количество интервалов, на которые нужно разделить значения при подсчете частот. В данном коде, значение `bins=8` указывает, что данные должны быть разделены на 8 интервалов.
4. `sort_index()`: Метод, применяемый к объекту Series, который сортирует значения по индексу. В данном коде, он используется для сортировки объекта Series `value_counts()` по возрастанию индексов, чтобы значения частот соответствовали правильным интервалам.

### Распределение относительных частот интервального вариационного ряда
Для получения распределения относительных частот интервального вариационного ряда, мы можем использовать следующий код, основанный на предыдущем коде:

```Python
rel_intervals_freq = pd.Series(data_sort).value_counts(bins=8).sort_index().values / len(data_sort)  
rel_intervals_freq = pd.DataFrame(rel_intervals_freq, index=intervals_mean, columns=["Относительная частота"]).T  
rel_intervals_freq
```


|                           | 25.40-26.80 | 26.80-28.20 | 28.20-29.60 | 29.60-31.00 | 31.00-32.40 | 32.40-33.80 | 33.80-35.20 | 35.20-36.60 |
| ------------------------- | ----------- | ----------- | ----------- | ----------- | ----------- | ----------- | ----------- | ----------- |
| **Относительная частота** | 0.06        | 0.16        | 0.2         | 0.26        | 0.19        | 0.08        | 0.03        | 0.02        |

В процессе получения распределения относительных частот интервального вариационного ряда используется аналогичный подход, но с небольшим отличием. Вместо простого подсчета абсолютных частот значений в объекте Series, мы выполняем дополнительное деление каждой абсолютной частоты на общее количество элементов, чтобы получить относительные частоты. 

```Python
rel_intervals_freq = pd.Series(data_sort).value_counts(bins=8).sort_index().values / len(data_sort)
```


### Полигон абсолютных и относительных частот интервального вариационного ряда

```Python
fig = px.bar(x=intervals_mean, y=freq_intervals.iloc[0], title='Гистограмма частот вариационного ряда')

fig.show()
```
![[newplot2.png]]


```Python
fig = px.bar(x=intervals_mean, y=rel_intervals_freq.values.tolist()[0], title='Гистограмма относительных частот вариационного ряда')

fig.show()
```
![[newplot3.png]]

## Эмпирическая функция распределения (ECDF)
%%
эмпирическую функцию распределения и построить график эмпирической функции распределения
%%
> Эмпирическая функция распределения (empirical cumulative distribution function, ECDF) - это статистическая функция, которая используется для описания и визуализации распределения вероятностей в наборе данных.
> 
> ECDF представляет собой функцию, которая оценивает вероятность того, что случайная переменная принимает значение, меньшее или равное определенной точке. Она строится путем подсчета относительной частоты значений в наборе данных, которые меньше или равны данной точке.

Для построения ECDF сначала сортируются значения в наборе данных по возрастанию. Затем для каждого значения рассчитывается относительная частота, которая представляет собой долю значений, меньших или равных данному значению, от общего числа значений. Наконец, строится график, где по оси X откладываются значения, а по оси Y - соответствующие относительные частоты.

ECDF позволяет наглядно представить распределение данных и увидеть, как часто значения находятся в определенном диапазоне. Она также может использоваться для сравнения распределений разных наборов данных или для сопоставления с теоретическими распределениями.

Эмпирическая функция распределения является полезным инструментом для исследования данных и предоставляет информацию о вероятностях и квантилях распределения.

```Python
emp_func = rel_intervals_freq.iloc[0].cumsum()  
emp_func.name = "F*"  
emp_func = pd.DataFrame(emp_func, index=intervals_mean).T  
emp_func
```
Метод `.cumsum()` используется для вычисления накопленной суммы значений. Он применяется к объекту Series или DataFrame и возвращает новый объект, содержащий накопленные суммы значений по каждой позиции.

Таким образом, код `emp_func = rel_intervals_freq.iloc[0].cumsum()` вычисляет накопленную сумму относительных частот для первого интервала в DataFrame `rel_intervals_freq` и сохраняет ее в переменную `emp_func`. Это позволяет построить эмпирическую функцию распределения на основе относительных частот.

## Среднее (Mean)
> **Среднее арифметическое** (Mean) - Cумма всех элементов исследования $y_1, y_2, \cdots , y_n$ деленная на их количество. Среднее значение набора измерений определяет **только лишь** центр распределения данных. Два набора измерений могут иметь очень разные частотные распределения, но равные средние. 

$$\overline x = \frac 1n \sum^n_{i=1} x_i$$
где
- $n$ - объем выборки, 
- $x_i$ - $i$-й элемент выборки

Среднее значение по **Генеральной совокупности** обозначается буквой $\mu$. Зачастую  $\mu$ это неизвестная константа которую мы бы хотели найти. 

Символ $\overline x$ в английском читается как "x bar" и обозначает **выборочное среднее**.

```Python
mean = np.mean(data)  
print(f'Выборочное среднее: {mean:.2f}')
```
Данный код использует функцию `np.mean()` из библиотеки NumPy для вычисления среднего значения (mean) исходных данных.
- `np.mean()`: Это функция из библиотеки NumPy, которая принимает массив данных в качестве аргумента и вычисляет среднее значение. В данном случае, `data` представляет собой массив данных.

Таким образом, код `mean = np.mean(data)` вычисляет среднее значение исходных данных `data` и сохраняет результат в переменной `mean`.

## Дисперсия (Variance) 
> **Дисперсией случайной величины** называется математическое ожидание квадрата отклонения этой случайной величины от ее математического ожидания. Дисперсия (Variance) в статистике является мерой разброса или вариации данных относительно их среднего значения. Она показывает, насколько значения признака отклоняются от среднего значения.
> 
> **Пояснения:** Зачастую математическое ожидание и среднее по совокупности это одно и то же, поэтому в данном определении используется термин математического ожидания. 

Дисперсия по выборочной совокупности обозначается как $s^2$

$$s^2 = \frac1{n - 1} \sum^n_{i=1} (y_i - \bar y)^2$$

в то время как дисперсия по генеральной совокупности обозначается как $\sigma^2$

$$\sigma^2 = \frac1n \sum^n_{i=1} (y_i - \bar y)^2$$

где
- $n$ - объем выборки,
- $y_i$ - элемент выборки,
- $\overline y$ - выборочное среднее,
- $y_i - \overline y$ - отклонение элемента выборки от выборочного среднего.

Дисперсия характеризует разброс случайной величины вокруг ее математического ожидания.

Корень из дисперсии называется стандартным отклонением.

```Python
var = np.var(data, ddof=1)  
print(f'Выборочная дисперсия: {var:.2f}')
```
В данном коде используется функция `np.var()` из библиотеки NumPy для вычисления дисперсии (variance) исходных данных.
- `np.var()`: Это функция из библиотеки NumPy, которая принимает массив данных в качестве аргумента и вычисляет дисперсию. В данном случае, `data` представляет собой массив данных.
- `ddof`: Это необязательный параметр функции `np.var()`, который определяет число степеней свободы. Значение `ddof=1` указывает, что используется поправка Бесселя для несмещенной оценки дисперсии, учитывающая размер выборки.

## Стандартное / Среднеквадратическое отклонение (Standard deviation)
Стандартное отклонение, также известное как среднеквадратическое отклонение, является мерой разброса или вариации данных относительно их среднего значения. Оно позволяет оценить, насколько значения признака отклоняются от среднего и предоставляет информацию о степени разброса данных. Корень из дисперсии называется средним квадратичным отклонением. 

- Для выборочной совокупности $$s = \sqrt{s^2}$$ 
- Для генеральной совокупности  $$\sigma = \sqrt{\sigma^2}$$

```Python
std = np.std(data, ddof=1)  
print(f'Среднеквадратическое отклонение: {std:.2f}')
```
- `np.std()`: Это функция из библиотеки NumPy, которая принимает массив данных в качестве аргумента и вычисляет стандартное отклонение. В данном случае, `data` представляет собой массив данных.
- `ddof`: Это необязательный параметр функции `np.std()`, который определяет число степеней свободы. Значение `ddof=1` указывает, что используется поправка Бесселя для несмещенной оценки стандартного отклонения, учитывающая размер выборки.

Таким образом, код `std = np.std(data, ddof=1)` вычисляет стандартное отклонение исходных данных `data` с использованием поправки Бесселя для несмещенной оценки стандартного отклонения, и результат сохраняется в переменной `std`.

## Коэффициент вариации (Coefficient of Variation)
> Коэффициент вариации является статистической мерой относительной изменчивости данных, которая позволяет сравнивать степень изменчивости различных наборов данных, учитывая их среднее значение

$$CV = \frac{s}{\overline x} \cdot 100$$

```Python
cv = (std / mean) * 100  
print(f'Коэффицент вариации: {cv:.2f}')
```
- `std`: Это значение стандартного отклонения, полученное ранее.
- `mean`: Это значение среднего значения, полученное ранее.

Таким образом, код `cv = (std / mean) * 100` вычисляет коэффициент вариации на основе стандартного отклонения и среднего значения, и результат сохраняется в переменной `cv`. Коэффициент вариации позволяет сравнивать относительную изменчивость между различными наборами данных, независимо от их единиц измерения, и может использоваться для оценки степени риска или неопределенности в данных.

## Доверительный интервал
> Доверительный интервал - это интервал значений, который охватывает неопределенность или вариабельность оценки параметра или статистики на основе имеющихся данных. Он предоставляет диапазон возможных значений, в котором находится истинное значение параметра с заданной вероятностью.

Доверительный интервал обычно выражается двумя значениями: нижней и верхней границей интервала. Например, доверительный интервал 95% для среднего значения означает, что существует 95% вероятность того, что истинное среднее значение находится в указанном интервале. Более узкий интервал указывает на более точную оценку, в то время как более широкий интервал указывает на большую неопределенность или вариабельность оценки.

Доверительный интервал зависит от уровня доверия, который определяет вероятность того, что истинное значение параметра находится в интервале. Наиболее распространенный уровень доверия - 95%, что означает, что в 95% случаев истинное значение будет попадать в доверительный интервал. Однако уровень доверия может быть выбран в зависимости от требуемой точности и надежности оценки.

Доверительные интервалы широко используются в статистике и исследованиях, чтобы оценить неопределенность оценок и сделать выводы на основе данных. Они позволяют учесть случайные флуктуации данных и предоставляют информацию о точности и надежности статистических оценок.

***

### Доверительный интервал для математического ожидания
Доверительный интервал для математического ожидания (среднего значения) можно выразить с использованием следующей формулы:

Для случая, когда известна генеральная совокупность и известна её стандартная ошибка $\sigma$ и размер выборки $n$, доверительный интервал для математического ожидания $\mu$ с заданным уровнем доверия $1 - \alpha$ вычисляется следующим образом:

$$\left( \overline x - z \cdot \frac{\sigma}{\sqrt{n}}, \overline x + z \cdot \frac{\sigma}{\sqrt{n}}\right)$$

где:
- $\overline x$- среднее значение выборки,
- $z$ - критическое значение стандартного нормального распределения, связанное с уровнем доверия $(1 - \alpha)$,
- $\sigma$ - стандартное отклонение генеральной совокупности,
- $n$ - размер выборки.

```Python
def cofidence_interval_for_expectation_t(data, confidence_prob):  
mean = np.mean(data)  
std = np.std(data, ddof=1)  
n = len(data)  
# t.ppf считает левосторонюю область, а нам требуется двустроняя  
alpha = (1 - confidence_prob) / 2  
gamma = 1 - alpha  
t_value = st.t.ppf(gamma, n - 1)  
delta = t_value * std / np.sqrt(n)  
return (mean - delta, mean + delta)  
  
cofidence_interval_for_expectation_t(data, confidence_prob)
```

```Python
(29.554737570230277, 36.48970687421421)
```

```Python
interval_expectation = st.t.interval(confidence_prob, df=data_len - 1, loc=mean, scale=st.sem(data))  
interval_expectation
```

```Python
(29.554737570230277, 36.48970687421421)
```

Для случая, когда известна только выборочная совокупность и неизвестна генеральная совокупность, доверительный интервал для математического ожидания $\mu$ с заданным уровнем доверия $(1 - \alpha)$ вычисляется следующим образом:

$$\left(\overline x - t(\gamma, n-1) \cdot \frac{s}{\sqrt{n}}, \quad \overline x + t(\gamma, n-1) \cdot \frac{s}{\sqrt{n}}\right)$$

где:
- $\overline x$- среднее значение выборки,
- $t$ - критическое значение распределения Стьюдента, связанное с уровнем доверия $(1 - \alpha)$ и степенями свободы $(n-1)$,
- $s$ - стандартное отклонение генеральной совокупности,
- $n$ - размер выборки.

Эти формулы позволяют определить диапазон значений, в котором с определенной вероятностью находятся истинные значения математического ожидания для выборочной и генеральной совокупности. Чем больше размер выборки и меньше стандартное отклонение, тем уже будет доверительный интервал и тем точнее будет оценка математического ожидания.

***

### Доверительный интервал для стандартного отклонения
Доверительный интервал для среднего квадратического отклонения (стандартного отклонения) представляет диапазон значений, в котором с определенной вероятностью находится истинное значение стандартного отклонения генеральной совокупности. Формула для расчета доверительного интервала может быть различной в зависимости от метода и предположений о распределении данных.

Одним из наиболее распространенных методов для расчета доверительного интервала для среднего квадратического отклонения является использование распределения хи-квадрат (chi-square distribution).

Формула для доверительного интервала для среднего квадратического отклонения на основе распределения хи-квадрат с уровнем доверия (1-α) и (n-1) степенями свободы выглядит следующим образом:

$$\left( (n - 1) \cdot \frac{S^2}{\chi^2_{left}}, \quad (n - 1) \cdot \frac{S^2}{\chi^2_{right}}\right) \text{ или } \left(\frac{S \sqrt{n-1}}{\chi_{left}}, \quad \frac{S \sqrt{n-1}}{\chi_{right}}\right)$$

где:
- $n$ - размер выборки,
- $S^2$ - выборочная дисперсия,
- $S$ - выборочное стандартное отклонение,
- $\chi_{left}$, $\chi^2_{left}$ и $\chi_{right}$, $\chi^2_{right}$ - значения из распределения хи-квадрат, связанные с уровнем доверия $(1 - \frac{\alpha}{2})$ и $(\frac{\alpha}{2})$ соответственно.

```Python
def confidence_interval_std(data, confidence_prob):  
std = np.std(data, ddof=1)  
n = len(data)  
chi_left = np.sqrt(st.chi2.ppf((1 + confidence_prob) / 2, n - 1))  
chi_right = np.sqrt(st.chi2.ppf((1 - confidence_prob) / 2, n - 1))  
return (std * np.sqrt(n - 1) / chi_left, std * np.sqrt(n - 1) / chi_right)  
  
confidence_interval_std(data, confidence_prob)
```

## Проверка статистических гипотез
Проверка статистических гипотез является важным инструментом в анализе данных и принятии решений на основе эмпирических наблюдений. Она позволяет нам делать выводы о параметрах или законах распределения генеральной совокупности на основе выборочных данных.

***

### Нулевая и альтернативная гипотезы
Статистическая гипотеза представляет собой утверждение о параметрах или законе распределения генеральной совокупности, которое мы хотим проверить с использованием доступных данных. В процессе проверки гипотезы формулируются нулевая и альтернативная гипотезы. Нулевая гипотеза $H_0$ предполагает, что никаких значимых различий или эффектов нет, тогда как альтернативная гипотеза $H_1$ предполагает наличие какого-то эффекта или различия.

Проверка гипотезы основывается на сборе выборочных данных и применении статистического теста. Статистический тест использует выборку для вычисления статистической меры (например, t-статистики, z-статистики, или других мер), которая позволяет сделать вывод о согласии или несогласии выборки с нулевой гипотезой. Результаты теста представляются в виде p-значения, которое указывает на вероятность получить такие или более экстремальные данные, если нулевая гипотеза верна.

В зависимости от полученного p-значения и уровня значимости (обычно обозначается $\alpha$), мы принимаем решение о отвержении или принятии нулевой гипотезы. Если p-значение меньше или равно $\alpha$, то мы отвергаем нулевую гипотезу в пользу альтернативной гипотезы, что указывает на наличие статистически значимого эффекта или различия. В противном случае, если p-значение больше $\alpha$, мы не отвергаем нулевую гипотезу, и делаем вывод о недостаточной статистической значимости.

***

### Ошибки первого и второго рода
Ошибки первого и второго рода являются двумя видами ошибок, которые могут возникнуть при статистической проверке гипотез. Они связаны с принятием или отвержением нулевой гипотезы на основе выборочных данных.

Ошибки первого рода, также известные как ложноположительные ошибки, возникают, когда мы отвергаем нулевую гипотезу, хотя она на самом деле верна. То есть мы делаем вывод о наличии эффекта или различия, когда его на самом деле нет. Вероятность ошибки первого рода обозначается символом α (уровень значимости). Чем ниже уровень значимости, тем меньше вероятность ошибки первого рода. Ошибки первого рода могут иметь серьезные последствия, особенно если они приводят к неправильным решениям или выводам.

Ошибки второго рода, также известные как ложноотрицательные ошибки, возникают, когда мы принимаем нулевую гипотезу, хотя она на самом деле неверна. То есть мы не обнаруживаем эффект или различие, когда они действительно существуют. Вероятность ошибки второго рода обозначается символом β. Чем ниже вероятность ошибки второго рода, тем выше мощность статистического теста, то есть способность обнаружить реальные различия или эффекты.

Ошибки первого и второго рода тесно связаны и обычно сопряжены между собой. При увеличении мощности статистического теста (уменьшении вероятности ошибки второго рода), вероятность ошибки первого рода может увеличиться. Поэтому в статистических исследованиях важно находить баланс между ошибками первого и второго рода, а также принимать во внимание практическую значимость результатов при принятии решений.

***

## Проверка гипотезы о том, что результаты получены из распределения Пуассона с помощью критерия Пирсона
Сформулируем 2 гипотезы $H_0$ и $H_1$
- $H_0$: Случайная величина имеет распределения Пуассона.  
- $H_1$: Случайная величина не имеет распределения Пуассона.

Вычислим ожидаемые частоты в каждом интервале, если бы выборка имела распределение Пуассона.  

Сначала найдем $\lambda$

$$\lambda \approx \bar{x}$$
$$\overline{x} = \frac{1}{n} \sum x_i n_i$$

```Python
lmbda = (data["X"] * data["n"]).sum() / n
lmbda
```

```Python
1.0099667774086378
```

Формула для расчета вероятности появления значения x в распределении Пуассона:
$$P(i)=\frac{\lambda^i \cdot e^{-\lambda}}{i!}$$  

где:
- $e$ - базисное число экспоненты (примерно равно 2.71828),
- $\lambda$ - параметр распределения Пуассона,
- $i$ - значение переменной.

Для вычисления ожидаемых частот в каждом интервале при предположении распределения Пуассона, используется следующая формула:
$$n' = nP_i$$
где:
- $n'$ - ожидаемая частота,
- $n$ - общее количество наблюдений или сумма наблюдаемых частот,
- $P_i$ - вероятность появления значения x в распределении Пуассона.

```Python
def expected_freq(x):  
p = st.poisson.pmf(x, mu=lmbda)  
return n * p  
  
data["n'"] = data["X"].apply(expected_freq)  
data["n'"]
```

```Python
0    109.633555
1    110.726248
2     55.914916
3     18.824069
4      4.752921
5      0.960058
Name: n', dtype: float64
```

Теперь вычислим значение статистики критерия Пирсона  
  
$$\chi^2 = \sum_{i=1}^{k} \frac{(n_i - n_i^*)^2}{n_i^*} = \frac{(\text{наблюдаемая частота} - \text{ожидаемая частота})^2}{\text{ожидаемая частота}}$$

```Python
chi2_value = ((data["n"] - data["n'"])**2 / data["n'"]).sum()  
chi2_value
```

```Python
1.2568488786645524
```

Определение критического значения

```Python
chi2_critical = st.chi2.ppf(1-alpha, df=df)  
chi2_critical
```

```Python
7.814727903251179
```

***

## Проверка гипотезы о том, что закон распределения генеральной совокупности является нормальным при уровне значимости $\alpha$
Сформулируем 2 гипотезы $H_0$ и $H_1$
- $H_0$: закон распределения генеральной совокупности является нормальным.  
- $H_1$: закон распределения генеральной совокупности не является нормальным.

Для проверки гипотезы о нормальности распределения воспользуемся критерием согласия хи-квадрат. Нужно вычислить теоретические (ожидаемые) частоты попадания значений в каждый интервал, если бы распределение было нормальным. Для этого воспользуемся формулой:  
$$P_i=P(x_i < X < x_{i+1})=Ф(\frac{x_{i+1} - \bar{x}}{S}) - Ф(\frac{x_{i} - \bar{x}}{S})$$  
$$f' = fP_i$$

```Python
p = st.norm.cdf((data["x_(i+1)"] - mean) / std) - st.norm.cdf((data["x_i"] - mean) / std)  
  
assert np.isclose(p.sum(), 1, rtol=.01), "Сумма теоретических оснований должна быть равна 1."  
  
data["f'"] = p * data["f"].sum()  
data["f'"]
```

```Python
0      1.989322
1      9.051664
2     28.600693
3     62.783364
4     95.779742
5    101.564606
6     74.862071
7     38.350836
8     13.650848
9      3.374717
Name: f', dtype: float64
```

Вычислим значение статистики критерия $\chi^2$:  
  
  
$$\chi^2 = \sum_{i=1}^{k} \frac{(f_i - f_i^*)^2}{f_i^*} = \frac{(\text{наблюдаемая частота} - \text{ожидаемая частота})^2}{\text{ожидаемая частота}}$$

```Python
chi2_value = ((data["f"] - data["f'"])**2 / data["f'"]).sum()  
chi2_value
```

```Python
1.2613069812716673
```

Определение критического значения
```Python
chi2_critical = st.chi2.ppf(1-alpha, df=df)  
chi2_critical
```

```Python
11.070497693516351
```

***

## Проверка гипотезы о том, что закон распределения генеральной совокупности является показательным при уровне значимости $\alpha$
Для проверки гипотезы о показательном распределения воспользуемся критерием согласия хи-квадрат. Нужно вычислить теоретические (ожидаемые) частоты попадания значений в каждый интервал, если бы распределение было равномерным. Для этого воспользуемся формулой:  
$$P_i=P(x_i < X < x_{i+1})=e^{-\lambda x_i} - e^{-\lambda x_{i+1}}$$  
$$f' = fP_i$$  
$$\lambda = 1/\bar{x}$$

```Python
lmbda = 1 / mean  
lmbda
```

```Python
0.3826530612244898
```


```Python
p = st.expon.cdf(data["x_(i+1)"], scale=1/lmbda) - st.expon.cdf(data["x_i"], scale=1/lmbda)  
  
assert np.isclose(p.sum(), 1, rtol=.01), "Сумма теоретических оснований должна быть равна 1."  
  
data["f'"] = p * data["f"].sum()  
data["f'"]
```

```Python
0     152.848836
1      92.944306
2      56.517565
3      34.367196
4      20.898001
5      12.707655
6       7.727269
7       4.698797
8       2.857244
9       1.737433
10      1.056498
Name: f', dtype: float64
```

Вычислим значение статистики критерия $\chi^2$:  
  
  
$$\chi^2 = \sum_{i=1}^{k} \frac{(f_i - f_i^*)^2}{f_i^*} = \frac{(\text{наблюдаемая частота} - \text{ожидаемая частота})^2}{\text{ожидаемая частота}}$$

```Python
chi2_value = ((data["f"] - data["f'"])**2 / data["f'"]).sum()  
chi2_value
```

```Python
12.292391902659396
```

Определим критическое значение

```Python
chi2_critical = st.chi2.ppf(1-alpha, df=df)  
chi2_critical
```

```Python
11.070497693516351
```

# Заключение
Мы познакомились с основными методами и классами matplotlib, знание которых необходимо для дальнейшего изучения курса. В случае, если представленной информации недостаточно, следует воспользоваться [официальной документацией matplotlib](https://matplotlib.org/stable/tutorials/introductory/index.html).

Мы познакомились с основными методами и классами pandas, знание которых необходимо для дальнейшего изучения курса. В случае, если представленной информации недостаточно, следует воспользоваться [официальной документацией pandas](https://pandas.pydata.org/docs/user_guide/index.html). 

***

## Источники
- []()
- []()
- []()